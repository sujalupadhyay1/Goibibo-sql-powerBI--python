{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f667c6f-40b8-4f18-a521-231ad9b50f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) SQL data preparation\n",
    "#- Built base view with consistent hotelid (text), price, rating, city, and amenities.\n",
    "#- Created price tier per city via quartiles (Budget/Mid/Luxury).\n",
    "#- Computed city landmark features (near_poi_share within 5 km, min_poi_km).\n",
    "- Aggregated reviews to review_count only (no average rating for Option B).\n",
    "- Assembled final training view with target = HotelData.rating and features = price, price_tier, city, amenity flags, review_count, near_poi_share, min_poi_km.\n",
    "#2) Data loading in Python\n",
    "- Connected to PostgreSQL and loaded the final feature view into a pandas DataFrame.\n",
    "- Split into train/test sets for evaluation.\n",
    "3) Modeling pipeline\n",
    "- Preprocessing with ColumnTransformer:\n",
    "- Numeric: StandardScaler (with_mean=False) for numeric columns.\n",
    "- Categorical: OneHotEncoder(handle_unknown=\"ignore\") for city and price_tier.\n",
    "- Model: RandomForestRegressor inside a Pipeline.\n",
    "4) Evaluation\n",
    "- Trained the pipeline and computed metrics: RMSE and RÂ² on the test set.\n",
    "- Trained a simple baseline (price-only LinearRegression) for sanity check.\n",
    "5) Troubleshooting handled\n",
    "- Fixed SQL identifier/type mismatches (hotelid as text; rating cast to float).\n",
    "- Resolved cast errors for text ratings in reviews; cleaned numeric strings where needed.\n",
    "- Corrected Python f-string credentials and sklearn version differences (RMSE computation).\n",
    "- Fixed permutation importance by running it on the transformed matrix and aligning feature names.\n",
    "6) Model interpretation\n",
    "- Computed permutation importance on transformed features to rank top drivers among numeric and one-hot categorical levels.\n",
    "7) Artifacts and inference\n",
    "- Saved the trained pipeline to model_rating_rf.pkl.\n",
    "- Saved the feature schema (numeric/categorical column lists) to model_schema.pkl.\n",
    "- Implemented an inference helper that:\n",
    "- Ensures missing columns are added with safe defaults.\n",
    "- Produces rating predictions for new batches.\n",
    "8) Current outcome\n",
    "- End-to-end workflow is complete: data prepared in SQL, model trained and evaluated, importances computed, artifacts stored, and batch inference verified.\n",
    "9) Optional next steps\n",
    "- Add K-fold cross-validation and small hyperparameter search (n_estimators, max_depth, min_samples_split).\n",
    "- Create a metrics JSON and top-20 features CSV for reporting.\n",
    "- Package an API endpoint (FastAPI/Flask) or CLI for batch scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03aaa32f-322c-427e-b67f-3738b4e2aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.43)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy psycopg2-binary\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0fbea2-3bb5-4734-bb0c-d6151d003070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.43)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.10)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.14.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.7 MB 2.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.7 MB 3.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.1/8.7 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.4/8.7 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.7/8.7 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.5/8.7 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.7/8.7 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.2/8.7 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.8/8.7 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.6/8.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.7 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 2.9 MB/s  0:00:03\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/38.5 MB 4.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.6/38.5 MB 4.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.6/38.5 MB 4.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.7/38.5 MB 4.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.5/38.5 MB 4.4 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 5.2/38.5 MB 4.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 6.0/38.5 MB 4.3 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.1/38.5 MB 4.3 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.6/38.5 MB 4.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 8.4/38.5 MB 4.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.2/38.5 MB 4.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.2/38.5 MB 4.0 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.2/38.5 MB 3.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 3.8 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 12.1/38.5 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 12.8/38.5 MB 3.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.9/38.5 MB 3.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 14.7/38.5 MB 3.9 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 15.5/38.5 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 16.5/38.5 MB 4.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.3/38.5 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.1/38.5 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.9/38.5 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.4/38.5 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 20.2/38.5 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 21.2/38.5 MB 3.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 22.3/38.5 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.3/38.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.1/38.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.9/38.5 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 25.7/38.5 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.5/38.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.3/38.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.3/38.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.1/38.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.1/38.5 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/38.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.1/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.7/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 3.8 MB/s  0:00:10\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy psycopg2-binary scikit-learn pandas numpy joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d19a24c-3553-4a64-98ec-7b67cec35f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"y_rating\"].astype(float)\n",
    "\n",
    "num_features = [\n",
    "    \"price\", \"review_count\", \"avg_review_rating\",\n",
    "    \"near_poi_share\", \"min_poi_km\"\n",
    "]\n",
    "cat_features = [\"city\", \"price_tier\"]\n",
    "\n",
    "# Binary flags are already numeric; add them to numeric block\n",
    "binary_flags = [\"has_wifi\", \"has_breakfast\", \"has_pool\", \"has_parking\", \"has_ac\"]\n",
    "num_features_all = num_features + binary_flags\n",
    "\n",
    "X = df[num_features_all + cat_features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a913a4-abe1-4abe-88b9-0c57fb541535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8040, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotelid</th>\n",
       "      <th>y_rating</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>price_tier</th>\n",
       "      <th>has_wifi</th>\n",
       "      <th>has_breakfast</th>\n",
       "      <th>has_pool</th>\n",
       "      <th>has_parking</th>\n",
       "      <th>has_ac</th>\n",
       "      <th>review_count</th>\n",
       "      <th>near_poi_share</th>\n",
       "      <th>min_poi_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628752c1d04899399ca38ad5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>deoghar</td>\n",
       "      <td>Mid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628752c1d04899399ca3919e</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>lonavala</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>628752bfd04899399ca37cf2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>pondicherry</td>\n",
       "      <td>Mid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628752c1d04899399ca38915</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4081.0</td>\n",
       "      <td>darjeeling</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761878</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628752c0d04899399ca3874b</td>\n",
       "      <td>4.4</td>\n",
       "      <td>935.0</td>\n",
       "      <td>madikeri</td>\n",
       "      <td>Budget</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.885612</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hotelid  y_rating   price         city price_tier  \\\n",
       "0  628752c1d04899399ca38ad5       4.3  1785.0      deoghar        Mid   \n",
       "1  628752c1d04899399ca3919e       4.2  6237.0     lonavala     Luxury   \n",
       "2  628752bfd04899399ca37cf2       4.1  1357.0  pondicherry        Mid   \n",
       "3  628752c1d04899399ca38915       3.9  4081.0   darjeeling     Luxury   \n",
       "4  628752c0d04899399ca3874b       4.4   935.0     madikeri     Budget   \n",
       "\n",
       "   has_wifi  has_breakfast  has_pool  has_parking  has_ac  review_count  \\\n",
       "0         1              0         0            1       1             0   \n",
       "1         1              0         1            1       1             0   \n",
       "2         1              0         1            1       1             0   \n",
       "3         0              0         0            0       0             0   \n",
       "4         0              0         0            1       0             0   \n",
       "\n",
       "   near_poi_share  min_poi_km  \n",
       "0        0.917431       0.072  \n",
       "1        0.736715       0.001  \n",
       "2        0.695652       1.100  \n",
       "3        0.761878       0.001  \n",
       "4        0.885612       0.009  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking dataset from postgress\n",
    "USER = \"postgres\"      \n",
    "PWD  = \"1234\"\n",
    "HOST = \"localhost\"\n",
    "PORT = 5432\n",
    "DB   = \"goibibo\"\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{USER}:{PWD}@{HOST}:{PORT}/{DB}\")\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM ml_rating_features_b\", con=engine)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93cb4d95-5070-41fe-989c-7cac47d04666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM ml_rating_features_v2\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4bc3f1c-7f7b-4694-b8bf-9fd262b5dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6627473-e347-4141-832a-d94f65b4acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build preprocessing + model pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features_all),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8661162-a0e2-4630-b87a-b18483e0dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 0.7717361295083767, 'R2': -0.003763453482726442}\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "preds = pipe.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = mse ** 0.5\n",
    "r2   = r2_score(y_test, preds)\n",
    "print({\"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3513e6d0-91ed-41df-b13d-a986b5549bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e74c4dd-7400-42fc-80da-e33838fd1807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Baseline_RMSE': 0.7586202574063992, 'Baseline_R2': 0.03006510309764976}\n"
     ]
    }
   ],
   "source": [
    "#Simple baseline for sanity\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse_base = mean_squared_error(y_test, base_preds)\n",
    "rmse_base = mse_base ** 0.5\n",
    "r2_base = r2_score(y_test, base_preds)\n",
    "print({\"Baseline_RMSE\": rmse_base, \"Baseline_R2\": r2_base})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0532e00-743e-438f-b4bd-48a909dc661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pipe.named_steps[\"preprocess\"]\n",
    "Xt_test = pre.transform(X_test)\n",
    "\n",
    "# Get transformed feature names robustly\n",
    "if hasattr(pre, \"get_feature_names_out\"):\n",
    "    feature_names = pre.get_feature_names_out()\n",
    "else:\n",
    "    # manual fallback\n",
    "    tx = {n: (est, cols) for n, est, cols in pre.transformers_ if n != \"remainder\"}\n",
    "    num_names = list(tx[\"num\"][1])\n",
    "    ohe = tx[\"cat\"][0].named_steps[\"onehot\"]\n",
    "    cat_levels = list(ohe.get_feature_names_out(tx[\"cat\"][1]))\n",
    "    feature_names = np.array(num_names + cat_levels, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adef35e9-3e40-4e2f-9bc7-84751600097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num__price                0.092072\n",
       "cat__city_mumbai          0.015803\n",
       "num__has_parking          0.008914\n",
       "cat__city_auli            0.005787\n",
       "cat__city_ranchi          0.005614\n",
       "num__has_pool             0.004296\n",
       "cat__price_tier_Budget    0.003756\n",
       "cat__city_manali          0.003335\n",
       "num__has_wifi             0.002721\n",
       "cat__city_madikeri        0.002350\n",
       "cat__city_almora          0.002216\n",
       "cat__city_munnar          0.001662\n",
       "cat__city_pushkar         0.001603\n",
       "cat__city_mathura         0.001321\n",
       "cat__city_abu             0.001080\n",
       "cat__city_dhanaulti       0.001075\n",
       "cat__city_ajmer           0.000941\n",
       "cat__city_gangtok         0.000739\n",
       "cat__city_khajuraho       0.000288\n",
       "cat__city_hampi           0.000162\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature importance (permutation)\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pre = pipe.named_steps[\"preprocess\"]\n",
    "Xt_test = pre.transform(X_test)\n",
    "\n",
    "# Dense matrix for permutation_importance\n",
    "Xt_test_dense = Xt_test.toarray() if hasattr(Xt_test, \"toarray\") else Xt_test\n",
    "\n",
    "# Get feature names\n",
    "if hasattr(pre, \"get_feature_names_out\"):\n",
    "    feature_names = pre.get_feature_names_out()\n",
    "else:\n",
    "    tx = {n: (est, cols) for n, est, cols in pre.transformers_ if n != \"remainder\"}\n",
    "    num_names = list(tx[\"num\"][1])\n",
    "    ohe = tx[\"cat\"][0].named_steps[\"onehot\"]\n",
    "    cat_levels = list(ohe.get_feature_names_out(tx[\"cat\"][1]))\n",
    "    feature_names = np.array(num_names + cat_levels, dtype=object)\n",
    "\n",
    "est = pipe.named_steps[\"model\"]\n",
    "\n",
    "r = permutation_importance(\n",
    "    est, Xt_test_dense, y_test, n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(len(r.importances_mean), len(feature_names))  # should match\n",
    "importances = pd.Series(r.importances_mean, index=feature_names).sort_values(ascending=False)\n",
    "importances.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "371349ca-b481-49cc-be76-d0bfd8cb02cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_schema.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save artifacts\n",
    "\n",
    "joblib.dump(pipe, \"model_rating_rf.pkl\")\n",
    "# Save columns to ensure consistent inference schema later\n",
    "schema = {\n",
    "    \"num_features\": num_features_all,\n",
    "    \"cat_features\": cat_features\n",
    "}\n",
    "joblib.dump(schema, \"model_schema.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7b1fb6f-dc03-4c5b-abe3-cd90c6a585da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.85285506, 3.72338726, 4.48290476, 3.92524786, 4.34992143])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference function example\n",
    "def predict_rating(batch_df: pd.DataFrame):\n",
    "    mdl = joblib.load(\"model_rating_rf.pkl\")\n",
    "    sch = joblib.load(\"model_schema.pkl\")\n",
    "    cols = sch[\"num_features\"] + sch[\"cat_features\"]\n",
    "    # Ensure missing columns exist\n",
    "    for c in cols:\n",
    "        if c not in batch_df:\n",
    "            batch_df[c] = 0 if c in sch[\"num_features\"] else \"unknown\"\n",
    "    return mdl.predict(batch_df[cols])\n",
    "\n",
    "# Example usage\n",
    "sample = X_test.iloc[:5].copy()\n",
    "predict_rating(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce680358-40c4-43d8-94cb-b80e4e12230e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Review Sentiment Classification\n",
    "\n",
    "#Goal: Predict sentiment category (Positive/Neutral/Negative) from review text (if available)\n",
    "#Models: Naive Bayes / Logistic Regression, evaluation via accuracy and F1-score\n",
    "\n",
    "Objective\n",
    "- Predict sentiment class (Positive/Neutral/Negative) from review_text to support downstream analytics and QA.\n",
    "Data & Labels\n",
    "- Built SQL view ml_review_text with columns: review_text and sentiment_label (derived from numeric rating: â¥4.0 Positive, â¤2.5 Negative, else Neutral).\n",
    "Models Trained\n",
    "- Pipeline A: TFâIDF + Logistic Regression (class_weight=\"balanced\", max_iter=200).\n",
    "- Pipeline B: TFâIDF + Multinomial Naive Bayes.\n",
    "Evaluation (heldâout test split)\n",
    "- Logistic Regression: accuracy â 0.774, weighted F1 â 0.793. Class-wise F1: Negative â 0.78, Neutral â 0.43, Positive â 0.87.\n",
    "- Multinomial NB: accuracy â 0.819, weighted F1 â 0.784. Class-wise F1: Negative â 0.77, Neutral â 0.22, Positive â 0.90.\n",
    "Choice\n",
    "- Selected Logistic Regression as final model because it maintains stronger balance across classes, \n",
    "  notably a substantially better Neutral-class F1 than NB (0.43 vs 0.22),while retaining high Positive performance.\n",
    "Artifacts\n",
    "- Saved model: review_sentiment_tfidf.pkl (TFâIDF + Logistic Regression).\n",
    "- Saved labels: review_sentiment_labels.pkl (class order for consistent inference).\n",
    "Inference\n",
    "- predict_sentiment(texts) loads artifacts and returns class predictions (and probabilities if available).\n",
    "  Verified examples produce sensible outputs (e.g., \"helpful staff\" â Positive; \"dirty sheets\" â Negative).\n",
    "- Monitoring & reporting:\n",
    "- Persist classification reports and confusion matrix each run; track per-class F1, especially Neutral.\n",
    "\n",
    "- Deployment:\n",
    "- Wrap predict_sentiment in an API for batch scoring; version artifacts (e.g., v1) and log model metadata (vocab_size, classes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2d5d915-4533-4d35-ab4b-771779367445",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = \"postgres\"        \n",
    "PWD  = \"1234\"           \n",
    "HOST = \"localhost\"\n",
    "PORT = 5432\n",
    "DB   = \"goibibo\"\n",
    "\n",
    "conn_str = f\"postgresql+psycopg2://{USER}:{PWD}@{HOST}:{PORT}/{DB}\"\n",
    "engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7294fb40-9ead-4194-af9b-29976f1b4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "engine = create_engine(conn_str)  # reuse from earlier\n",
    "df = pd.read_sql(\"SELECT review_text, sentiment_label FROM ml_review_text\", con=engine)\n",
    "\n",
    "# Drop empties and keep 3 classes only\n",
    "df = df.dropna(subset=[\"review_text\", \"sentiment_label\"])\n",
    "X_text = df[\"review_text\"].astype(str)\n",
    "y = df[\"sentiment_label\"].astype(\"category\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8843baed-e59a-405a-b1c9-8048f41834e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good and excellent hotel with budget. Very nic...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nice n neat rooms, good services, not having r...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very nice hotel to stay at any time..nice room...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice hotel in vizag,and value of money, friend...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very nice and very comfartable  and very good ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good Hotel, very good room neat and clean ,Hop...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>srives Vere  poor mayenetenas good  staf peopl...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hotel location is good but service is very poo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hotel is good is staff are very friendly good ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Best Hotel , rooms is very good  , very good s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>staff and service was very good.Stay was reall...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Food is average. any thing you order takes mor...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it was very nice stay for me in Visakhapatnam ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Good service  and responsive on duties</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>very good service staff stay in two time recom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>no proper water services i m getting problems ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clean and good rooms but half of the channels ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hotel is good in all terms. Clean, location, s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Clean and nice hotel. Good service and got it ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Good hotel to stay..very cleaned room &amp; peace ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bad Service and Bad food quality there are lot...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>very bad service...no response..careless ..no ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good hotel near to railway station, rtc comple...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>It was a pleasant stay. Hotel is very close to...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worse hotel  not at all value for money\\n i wi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Room service is very poor.hotel is fine.no coo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>really nice hotel.pleasant stay. staff were pr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hi yes this is really nice staying room, I rea...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Good hotel to stay as it is near and accessibl...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stay is  very good. very neat and clean mainta...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>good stay..but the problem is with check in ti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nice stay. Check with reception for early chec...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Hotel stay is good  and please try food is tas...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Value for the money, Rooms are OK. Batch Room ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Service quality was very poor ...not even regu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A newly constructed hotel with very good rooms...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Very clean and nice rooms to stay very calm lo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>very good service quality at reasonable prices...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>very good maintains \\nboys services is good , ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>don't stay this hotel iam booking this hotel 2...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Hotel staff was not at all helpful...their che...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Most friendly and helpful receptionist ever, s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Very good hotel at cheap rate. U may not find ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Really the rooms are very good.\\nThis was the ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>location and room was ok.Service was to much p...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Very good service for the amount I paid. Most ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>it was good comfortable and nice stay. value f...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>At the time of check-in,the receptionist said ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Stay in the Hotel Very Bad experience Front of...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This is a good budget friendly hotel with all ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_text sentiment_label\n",
       "0   Good and excellent hotel with budget. Very nic...        Positive\n",
       "1   nice n neat rooms, good services, not having r...        Positive\n",
       "2   very nice hotel to stay at any time..nice room...        Positive\n",
       "3   nice hotel in vizag,and value of money, friend...        Positive\n",
       "4   very nice and very comfartable  and very good ...        Positive\n",
       "5   Good Hotel, very good room neat and clean ,Hop...        Positive\n",
       "6   srives Vere  poor mayenetenas good  staf peopl...        Positive\n",
       "7   Hotel location is good but service is very poo...        Negative\n",
       "8   Hotel is good is staff are very friendly good ...        Positive\n",
       "9   Best Hotel , rooms is very good  , very good s...        Positive\n",
       "10  staff and service was very good.Stay was reall...        Positive\n",
       "11  Food is average. any thing you order takes mor...         Neutral\n",
       "12  it was very nice stay for me in Visakhapatnam ...        Positive\n",
       "13             Good service  and responsive on duties        Positive\n",
       "14  very good service staff stay in two time recom...        Positive\n",
       "15  no proper water services i m getting problems ...        Negative\n",
       "16  Clean and good rooms but half of the channels ...         Neutral\n",
       "17  Hotel is good in all terms. Clean, location, s...        Positive\n",
       "18  Clean and nice hotel. Good service and got it ...        Positive\n",
       "19  Good hotel to stay..very cleaned room & peace ...        Positive\n",
       "20  Bad Service and Bad food quality there are lot...        Negative\n",
       "21  very bad service...no response..careless ..no ...        Negative\n",
       "22  good hotel near to railway station, rtc comple...        Positive\n",
       "23  It was a pleasant stay. Hotel is very close to...        Positive\n",
       "24  worse hotel  not at all value for money\\n i wi...        Negative\n",
       "25  Room service is very poor.hotel is fine.no coo...         Neutral\n",
       "26  really nice hotel.pleasant stay. staff were pr...        Positive\n",
       "27  Hi yes this is really nice staying room, I rea...        Positive\n",
       "28  Good hotel to stay as it is near and accessibl...        Positive\n",
       "29  stay is  very good. very neat and clean mainta...        Positive\n",
       "30  good stay..but the problem is with check in ti...        Positive\n",
       "31  Nice stay. Check with reception for early chec...        Positive\n",
       "32  Hotel stay is good  and please try food is tas...        Positive\n",
       "33  Value for the money, Rooms are OK. Batch Room ...        Positive\n",
       "34  Service quality was very poor ...not even regu...        Negative\n",
       "35  A newly constructed hotel with very good rooms...        Positive\n",
       "36  Very clean and nice rooms to stay very calm lo...        Positive\n",
       "37  very good service quality at reasonable prices...        Positive\n",
       "38  very good maintains \\nboys services is good , ...        Positive\n",
       "39  don't stay this hotel iam booking this hotel 2...        Negative\n",
       "40  Hotel staff was not at all helpful...their che...        Negative\n",
       "41  Most friendly and helpful receptionist ever, s...        Positive\n",
       "42  Very good hotel at cheap rate. U may not find ...        Positive\n",
       "43  Really the rooms are very good.\\nThis was the ...        Negative\n",
       "44  location and room was ok.Service was to much p...        Negative\n",
       "45  Very good service for the amount I paid. Most ...        Positive\n",
       "46  it was good comfortable and nice stay. value f...         Neutral\n",
       "47  At the time of check-in,the receptionist said ...        Negative\n",
       "48  Stay in the Hotel Very Bad experience Front of...        Negative\n",
       "49  This is a good budget friendly hotel with all ...        Positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT review_text, sentiment_label FROM ml_review_text LIMIT 50\", con=engine)\n",
    "display(df)         \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd4273-e821-444d-bdaf-3f7a0eccde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 â Build TFâIDF + model pipelines\n",
    "\n",
    "#Option A: Logistic Regression (strong baseline).\n",
    "\n",
    "#Option B: Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d70ae970-281d-49cf-9ea7-03ba8c2a2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Common vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2),\n",
    "    max_df=0.9,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "logreg_pipe = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, n_jobs=-1, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13b2153b-45c6-491b-8be3-8e4233473ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression {'accuracy': 0.7744827948102379, 'f1_weighted': 0.7922559944874592}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.79      0.78     27715\n",
      "     Neutral       0.35      0.56      0.43     20771\n",
      "    Positive       0.93      0.81      0.87    103968\n",
      "\n",
      "    accuracy                           0.77    152454\n",
      "   macro avg       0.68      0.72      0.69    152454\n",
      "weighted avg       0.82      0.77      0.79    152454\n",
      "\n",
      "MultinomialNB {'accuracy': 0.8182664934996786, 'f1_weighted': 0.7843372942296177}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.80      0.77     27715\n",
      "     Neutral       0.55      0.14      0.22     20771\n",
      "    Positive       0.85      0.96      0.90    103968\n",
      "\n",
      "    accuracy                           0.82    152454\n",
      "   macro avg       0.71      0.63      0.63    152454\n",
      "weighted avg       0.79      0.82      0.78    152454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def train_eval(pipe, name):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1w = f1_score(y_test, preds, average=\"weighted\")\n",
    "    print(name, {\"accuracy\": acc, \"f1_weighted\": f1w})\n",
    "    print(classification_report(y_test, preds))\n",
    "    return pipe\n",
    "\n",
    "logreg_model = train_eval(logreg_pipe, \"LogisticRegression\")\n",
    "nb_model = train_eval(nb_pipe, \"MultinomialNB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7271c7d-ae86-4997-9217-8c16c9d84559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_sentiment_labels.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pick the best and persist\n",
    "import joblib\n",
    "\n",
    "best_model = logreg_model  # or nb_model if it wins\n",
    "joblib.dump(best_model, \"review_sentiment_tfidf.pkl\")\n",
    "\n",
    "# Save label order for consistent inference\n",
    "label_order = list(best_model.classes_)\n",
    "joblib.dump(label_order, \"review_sentiment_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca5fc527-0933-4f4f-af37-496f363c2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "#Inference helper\n",
    "import numpy as np\n",
    "\n",
    "def predict_sentiment(texts):\n",
    "    mdl = joblib.load(\"review_sentiment_tfidf.pkl\")\n",
    "    labels = joblib.load(\"review_sentiment_labels.pkl\")\n",
    "    probs = mdl.predict_proba(texts) if hasattr(mdl, \"predict_proba\") else None\n",
    "    preds = mdl.predict(texts)\n",
    "    return preds, probs, labels\n",
    "\n",
    "# Example\n",
    "preds, probs, labels = predict_sentiment(pd.Series([\n",
    "    \"Room was clean and staff were very helpful\",\n",
    "    \"Noisy AC, dirty sheets, terrible experience\"\n",
    "]))\n",
    "print(preds.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d13805-db01-408f-8eca-ed6a2dea17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emerging Location Clustering\n",
    "\n",
    "#Goal: Identify clusters of similar-performing cities to guide expansion\n",
    "#Technique: K-means or hierarchical clustering on listing growth, price level, rating trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ab899ec-5be9-4e3e-901d-2bfa5dadcdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "engine = create_engine(conn_str)\n",
    "city = pd.read_sql(\"SELECT * FROM ml_city_features\", con=engine)\n",
    "\n",
    "# Keep available numeric features (no dates => no growth/trend)\n",
    "city2 = city.copy()\n",
    "city2 = city2.dropna(subset=[\"price_level\"])  # ensure price exists\n",
    "city2[\"listings_90d\"] = city2[\"listings_90d\"].fillna(0)\n",
    "\n",
    "X = city2[[\"listings_90d\",\"price_level\"]].astype(float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e13fc58-3dc4-4093-9d70-8cdd73a27743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>listings_90d</th>\n",
       "      <th>listings_prev90d</th>\n",
       "      <th>listing_growth</th>\n",
       "      <th>price_level</th>\n",
       "      <th>rating_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abu</td>\n",
       "      <td>105</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agra</td>\n",
       "      <td>298</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1226.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ajmer</td>\n",
       "      <td>123</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alleppey</td>\n",
       "      <td>156</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>almora</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>auli</td>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3622.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bankura</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binsar</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3136.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chandigarh</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cherrapunji</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  listings_90d listings_prev90d listing_growth  price_level  \\\n",
       "0          abu           105             None           None       2400.0   \n",
       "1         agra           298             None           None       1226.5   \n",
       "2        ajmer           123             None           None       1297.0   \n",
       "3     alleppey           156             None           None       2337.0   \n",
       "4       almora            25             None           None       2543.0   \n",
       "5         auli            43             None           None       3622.0   \n",
       "6      bankura             9             None           None       1837.0   \n",
       "7       binsar            20             None           None       3136.5   \n",
       "8   chandigarh           300             None           None       1464.0   \n",
       "9  cherrapunji             7             None           None       2249.0   \n",
       "\n",
       "   rating_trend  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           0.0  \n",
       "6           0.0  \n",
       "7           0.0  \n",
       "8           0.0  \n",
       "9           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM ml_city_features LIMIT 10;\", con=engine)\n",
    "display(df)         \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33c95535-02c2-4ca0-b18c-4902c10d3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette: {3: 0.4595548318325597, 4: 0.393625176279665, 5: 0.4278450652851638, 6: 0.4280500043515687} best_k: 3\n"
     ]
    }
   ],
   "source": [
    "#Pick k by silhouette and fit\n",
    "ks = [3,4,5,6]\n",
    "scores = {}\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(Xs)\n",
    "    scores[k] = silhouette_score(Xs, labels)\n",
    "best_k = max(scores, key=scores.get)\n",
    "print(\"silhouette:\", scores, \"best_k:\", best_k)\n",
    "\n",
    "km = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "city2[\"cluster\"] = km.fit_predict(Xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae7bed90-42fe-4735-96ce-6781d601d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listings_90d</th>\n",
       "      <th>price_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.5</td>\n",
       "      <td>2175.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229.5</td>\n",
       "      <td>2104.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8423.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         listings_90d  price_level\n",
       "cluster                           \n",
       "0                45.5      2175.50\n",
       "1               229.5      2104.75\n",
       "2                 6.0      8423.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['city_clustering_kmeans.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize clusters and export\n",
    "summary = city2.groupby(\"cluster\")[[\"listings_90d\",\"price_level\"]].median().round(2)\n",
    "display(summary)\n",
    "\n",
    "city2.to_csv(\"city_clusters.csv\", index=False)\n",
    "\n",
    "import joblib\n",
    "joblib.dump({\"scaler\": scaler, \"kmeans\": km, \"features\": [\"listings_90d\",\"price_level\"]},\n",
    "            \"city_clustering_kmeans.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb36164d-7b78-445c-84b0-345fa6f8b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(\"city_cluster_summary.csv\")\n",
    "city2.to_csv(\"city_clusters.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4ea5b07-48dd-4cc7-87c2-7c54787ff1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(conn_str)\n",
    "city = pd.read_sql(\"SELECT * FROM ml_city_features\", con=engine)\n",
    "\n",
    "# Filter: ensure growth is defined and enough volume in either window\n",
    "city = city.dropna(subset=[\"listing_growth\",\"price_level\",\"rating_trend\"])\n",
    "city = city[(city[\"listings_90d\"] >= 10) | (city[\"listings_prev90d\"] >= 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b56400ff-1dcc-4d49-af7a-feb4b6cc752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>listings_90d</th>\n",
       "      <th>listings_prev90d</th>\n",
       "      <th>listing_growth</th>\n",
       "      <th>price_level</th>\n",
       "      <th>rating_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abu</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2409.0</td>\n",
       "      <td>-7.141686e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agra</td>\n",
       "      <td>166</td>\n",
       "      <td>132</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>1206.5</td>\n",
       "      <td>2.086595e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ajmer</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>-3.871784e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alleppey</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>1.127695e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>almora</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>-9.350026e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>auli</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>3622.0</td>\n",
       "      <td>6.616023e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bankura</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>4.092030e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binsar</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3382.0</td>\n",
       "      <td>1.571005e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chandigarh</td>\n",
       "      <td>157</td>\n",
       "      <td>143</td>\n",
       "      <td>0.097902</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>-6.180459e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cherrapunji</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>-7.644415e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  listings_90d  listings_prev90d  listing_growth  price_level  \\\n",
       "0          abu            60                45        0.333333       2409.0   \n",
       "1         agra           166               132        0.257576       1206.5   \n",
       "2        ajmer            62                61        0.016393       1233.0   \n",
       "3     alleppey            72                84       -0.142857       2636.0   \n",
       "4       almora            17                 8        1.125000       2543.0   \n",
       "5         auli            18                25       -0.280000       3622.0   \n",
       "6      bankura             7                 2        2.500000       1837.0   \n",
       "7       binsar            13                 7        0.857143       3382.0   \n",
       "8   chandigarh           157               143        0.097902       1484.0   \n",
       "9  cherrapunji             3                 4       -0.250000       2249.0   \n",
       "\n",
       "   rating_trend  \n",
       "0 -7.141686e-09  \n",
       "1  2.086595e-08  \n",
       "2 -3.871784e-09  \n",
       "3  1.127695e-08  \n",
       "4 -9.350026e-08  \n",
       "5  6.616023e-08  \n",
       "6  4.092030e-08  \n",
       "7  1.571005e-08  \n",
       "8 -6.180459e-09  \n",
       "9 -7.644415e-09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM public.ml_city_features LIMIT 10 \", con=engine)\n",
    "display(df)         \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34f972b8-bb6b-4f42-b05f-23d7828dc9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette: {3: 0.2863863411537589, 4: 0.27793215328953397, 5: 0.2809281747653934, 6: 0.26948262525259375} best_k: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X = city[[\"listing_growth\",\"price_level\",\"rating_trend\"]].astype(float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "scores = {}\n",
    "for k in [3,4,5,6]:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(Xs)\n",
    "    scores[k] = silhouette_score(Xs, labels)\n",
    "best_k = max(scores, key=scores.get)\n",
    "print(\"silhouette:\", scores, \"best_k:\", best_k)\n",
    "\n",
    "km = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "city[\"cluster\"] = km.fit_predict(Xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84001480-318e-4907-8a49-82d5780e5e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_growth</th>\n",
       "      <th>price_level</th>\n",
       "      <th>rating_trend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.125</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         listing_growth  price_level  rating_trend\n",
       "cluster                                           \n",
       "0                 0.048       1580.0          -0.0\n",
       "1                -0.100       2636.0           0.0\n",
       "2                 1.125       2543.0           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['city_clustering_kmeans_v2.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = city.groupby(\"cluster\")[[\"listing_growth\",\"price_level\",\"rating_trend\"]].median().round(3)\n",
    "display(summary)\n",
    "\n",
    "city.to_csv(\"city_clusters_v2.csv\", index=False)\n",
    "summary.to_csv(\"city_cluster_summary_v2.csv\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump({\"scaler\": scaler, \"kmeans\": km, \"features\": [\"listing_growth\",\"price_level\",\"rating_trend\"]},\n",
    "            \"city_clustering_kmeans_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cdc3d-b593-48c8-86e4-5364b15a393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective\n",
    "- Identify clusters of similar-performing cities to guide expansion, using three features: listing_growth, price_level, rating_trend.\n",
    "Data view\n",
    "- Built SQL view ml_city_features with:\n",
    "- listings_90d, listings_prev90d (recent vs prior 90-day counts).\n",
    "- listing_growth = (listings_90d - listings_prev90d) / listings_prev90d.\n",
    "- price_level = median recent price.\n",
    "- rating_trend = monthly rating slope (proxy from temporal ordering).\n",
    "- Applied support filter in Python: keep cities where max(listings_90d, listings_prev90d) â¥ 10 and drop rows with nulls.\n",
    "Modeling\n",
    "- Features used for clustering: [\"listing_growth\", \"price_level\", \"rating_trend\"].\n",
    "- Standardized features with StandardScaler.\n",
    "- Chose number of clusters by silhouette over k â {3,4,5,6}; best_k = 3 on this data.\n",
    "- Trained K-means (random_state=42, n_init=10) and assigned cluster labels to cities.\n",
    "Results (cluster medians)\n",
    "- Cluster 0: listing_growth â 0.048, price_level â 1580, rating_trend â ~0.\n",
    "- Cluster 1: listing_growth â -0.100, price_level â 2636, rating_trend â ~0.\n",
    "- Cluster 2: listing_growth â 1.125, price_level â 2543, rating_trend â ~0.\n",
    "- Silhouette scores by k (example): {3: ~0.286, 4: ~0.278, 5: ~0.281, 6: ~0.269}; selected k=3.\n",
    "Interpretation\n",
    "- Cluster 2 (high growth, midâhigh price): expansion priority; add supply and marketing.\n",
    "- Cluster 0 (modest growth, lowâmid price): selective growth; maintain competitive pricing.\n",
    "- Cluster 1 (flat/negative growth, high price): cautious investment; focus on quality/price alignment.\n",
    "Deliverables saved\n",
    "- City assignments: city_clusters_v2.csv\n",
    "- Cluster summary (medians): city_cluster_summary_v2.csv\n",
    "- Model artifacts: city_clustering_kmeans_v2.pkl\n",
    "- Meta: features used and silhouette scores (v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ddce2-731a-47f8-aa2c-b756fe2b19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating Prediction Model\n",
    "\n",
    "Built features from price tier, amenities, city/landmark metrics, and review_count; trained a RandomForestRegressor in a Pipeline; evaluated with RMSE and RÂ²; saved the trained pipeline and schema; added batch inference helper.\n",
    "\n",
    "Review Sentiment Classification\n",
    "\n",
    "Prepared review_text with 3-class labels; trained TFâIDF + Logistic Regression and TFâIDF + Multinomial Naive Bayes; selected Logistic Regression for better class balance; evaluated with accuracy and weighted F1; saved model and labels; added inference helper.\n",
    "\n",
    "Emerging Location Clustering\n",
    "\n",
    "Created ml_city_features with listing_growth, price_level, rating_trend; standardized features; chose k by silhouette (best_k = 3); trained Kâmeans; exported city assignments, cluster medians, and model artifact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
